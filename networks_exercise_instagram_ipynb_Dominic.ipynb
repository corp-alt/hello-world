{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "networks_exercise_instagram.ipynb - Dominic",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/corp-alt/hello-world/blob/master/networks_exercise_instagram_ipynb_Dominic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L53IOJPRDgf",
        "colab_type": "text"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQfgQ9a5QfTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# STandard stuff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import itertools # Python's amazing iteration & combination library"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvZdilOdQ11B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For visualization\n",
        "!pip install -U bokeh\n",
        "!pip install -q holoviews\n",
        "\n",
        "# Import the libraries and link to the bokeh backend\n",
        "import holoviews as hv\n",
        "from holoviews import opts\n",
        "hv.extension('bokeh')\n",
        "from bokeh.plotting import show\n",
        "\n",
        "# Setting the default figure size a bit larger\n",
        "defaults = dict(width=750, height=750, padding=0.1,\n",
        "                xaxis=None, yaxis=None)\n",
        "hv.opts.defaults(\n",
        "    opts.EdgePaths(**defaults), opts.Graph(**defaults), opts.Nodes(**defaults))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tilWBAYXQoUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network Stuff\n",
        "import networkx as nx\n",
        "import community # `python-louvain` is implemented here\n",
        "from networkx.algorithms import bipartite # bipartite NW algos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmdoxqxQRKiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Blockmodel Stuff\n",
        "!wget https://github.com/CALDISS-AAU/sdsphd19_coursematerials/raw/master/wednesday_network-blockmodeling/blockmodeling_material.zip # downloading module and data files to googe drive session\n",
        "!unzip 'blockmodeling_material.zip' # unzipping\n",
        "\n",
        "# import the necessary modules\n",
        "import blockmodeling as bm\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sc\n",
        "import scipy.cluster.hierarchy as sch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YtLz6yARvu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# API&Scraping&instagramm\n",
        "!pip3 install instaloader # Installing instaloader\n",
        "import instaloader\n",
        "L = instaloader.Instaloader()\n",
        "\n",
        "import requests as rq # The requests library handles \"requests\" to APIs similar to a browser that requests a webpage given a URL\n",
        "from nltk.tokenize import TweetTokenizer # A bit of a transition into NLP. The tweet tokenizer from the NLTK library will help us extract the hashtags from post-text\n",
        "tknzr = TweetTokenizer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtXZbE0gQdVf",
        "colab_type": "text"
      },
      "source": [
        "# Task\n",
        "\n",
        "So guys, now its time to put it all together. Take the two notebooks by Carl, and Daniel, and Carl, and Ddo the following:\n",
        "\n",
        "1. Extract Instagram Tag infos of your choice\n",
        "2. Generate a bipartite User-Tag network\n",
        "3. Project it on either the user or the tag mode (your choice)\n",
        "4. Apply blockmodeling on it \n",
        "\n",
        "* [Networks general: Daniel](https://colab.research.google.com/github/CALDISS-AAU/sdsphd19_coursematerials/blob/master/notebooks/CALDISS_PHD_Intro_networks.ipynb#&offline=true&sandboxMode=true)\n",
        "* [Blockmodels: Carl](https://colab.research.google.com/github/CALDISS-AAU/sdsphd19_coursematerials/blob/master/wednesday_network-blockmodeling/Lab_Blockmodeling.ipynb#&offline=true&sandboxMode=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJUQB3uASjJ5",
        "colab_type": "text"
      },
      "source": [
        "# Getting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPBQFVS9SlLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instagram base url preffix\n",
        "tagurl_prefix = 'https://www.instagram.com/explore/tags/'\n",
        "\n",
        "# suffix to append to tag request url to retrieve data in JSON format\n",
        "tagurl_suffix = '/?__a=1'\n",
        "\n",
        "# suffix to end cursor when requesting posts by tag\n",
        "tagurl_endcursor = '&max_id='\n",
        "\n",
        "# a generic media post preffix (concat with media shortcode to view)\n",
        "posturl_prefix = 'https://www.instagram.com/p/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kudm7HruSnet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Find your own instagramm tag to explore!!!!!\n",
        "#\n",
        "tags = ['faxekondi']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF91Kcc4StWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# urls to initial tags using the above url-components\n",
        "queries = [ tagurl_prefix + tag + tagurl_suffix for tag in tags ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgLWIJ8sS9nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the data\n",
        "edges = []\n",
        "for q in queries:    \n",
        "    for i in range(10): # how many iterations/deepth ?\n",
        "      r = rq.get(q).json()\n",
        "      end_cursor = r['graphql']['hashtag']['edge_hashtag_to_media']['page_info']['end_cursor']\n",
        "      edges.extend(r['graphql']['hashtag']['edge_hashtag_to_media']['edges'])\n",
        "      print(i)\n",
        "      q = q + tagurl_endcursor + end_cursor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjxRqCz0TH-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post_dicts = [] #empty list\n",
        "\n",
        "for post in edges: #iterate all raw posts\n",
        "\n",
        "  if post['node']['edge_media_to_caption']['edges'] == []: # hop to the next if no text in the post\n",
        "    continue\n",
        "    \n",
        "  post_dict = {} # empty dictionary\n",
        "  id_owner = post['node']['owner']['id'] # pick out user-id\n",
        "  shortcode = post['node']['shortcode'] # pick out short post identifier\n",
        "  text = post['node']['edge_media_to_caption']['edges'][0]['node']['text'] # pick out post text\n",
        "  \n",
        "  # Pick hashtags from text\n",
        "  tokens = tknzr.tokenize(text)\n",
        "  tags = [x.strip('#') for x in tokens if x.startswith('#')]\n",
        "\n",
        "  # fill in dictionary with values\n",
        "  post_dict['id_owner'] = id_owner\n",
        "  post_dict['shortcode'] = shortcode\n",
        "  post_dict['tags'] = tags\n",
        "  post_dict['text'] = text\n",
        "\n",
        "  post_dicts.append(post_dict) #append the dictionary to a list of post-dictionaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JKaWfzFTNMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create DF\n",
        "posts_df = pd.DataFrame(post_dicts)\n",
        "\n",
        "# Remove hashtags that are not a hashtag (emptyspace & mistakes)\n",
        "posts_df['tags'] = posts_df['tags'].map(lambda t: [x for x in t if x.isalnum()])\n",
        "\n",
        "# Kick out posts with 0 hashtags\n",
        "posts_df = posts_df[posts_df['tags'].map(len) != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr0IEYwNTh2Q",
        "colab_type": "text"
      },
      "source": [
        "# Create a graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBcRNVdZTri9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new graph\n",
        "B = nx.Graph()\n",
        "# We need to specify the nodes for level 0 - this will be our users\n",
        "B.add_nodes_from(list(set(posts_df.id_owner)), bipartite= 1)\n",
        "# Then we need to add hashtags nodes as level 1 nodes\n",
        "B.add_nodes_from(list(set(itertools.chain(*posts_df.tags))), bipartite= 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjA_UC_4T1u_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This quick loop will generate edges between users and hashtags\n",
        "# Every time someone mentions a #hashtag, a link is created\n",
        "\n",
        "bi_edges = []\n",
        "for i in posts_df[['id_owner','tags']].iterrows(): # we do this row-by-row since each row is a post\n",
        "  id_owner = i[1]['id_owner']\n",
        "  for j in i[1]['tags']:\n",
        "    bi_edges.append((id_owner, j)) # edges are appended to a list as a tuple (id_owner, hashtag)\n",
        "\n",
        "# Let's add the edges to our graph\n",
        "B.add_edges_from(bi_edges)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdV7C7PThlHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i[1].tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IuIHgCiUIv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract a set of nodes with level 0\n",
        "top_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==0}\n",
        "\n",
        "# the remaining nodes are then level 1\n",
        "bottom_nodes = set(B) - top_nodes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqef7qUlUNq0",
        "colab_type": "text"
      },
      "source": [
        "# Now your turn!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4HSrCYsixN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mat.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycAnqnufgzjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mat.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_R3TA0kjeoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind = np.unravel_index(np.argmax(mat, axis=None), mat.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHGGShAgj3q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KHUeb5mkBMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nodelabels[346], nodelabels[390]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObFxGl5TkQw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "posts_df[posts_df['id_owner'] == nodelabels[346]]['tags']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG5MuG0LlAiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(posts_df['id_owner'] == nodelabels[346]).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLTpjWm2URGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's project this graph using a weighted projection\n",
        "G_proj = bipartite.weighted_projected_graph(B, top_nodes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWPzKZxvemJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Again, we can identify communities\n",
        "bi_communities = community.best_partition(G_proj, resolution = 1)\n",
        "nx.set_node_attributes(G_proj, bi_communities, 'community')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcNOuMDFfC1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate eigenvector centrality and set it as an attribute\n",
        "bi_eigenvector = nx.eigenvector_centrality(G_proj)\n",
        "nx.set_node_attributes(G_proj, bi_eigenvector, 'eigenvector_centrality')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i2Hfk1JfC8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new attribute \"activity\" - or propensity to spam\n",
        "nx.set_node_attributes(G_proj, dict(posts_df.id_owner.value_counts()), 'activity' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1CxXTl8fDCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do spammers connect more in terms of spamming about the same stuff?\n",
        "print(nx.numeric_assortativity_coefficient(G_proj,'activity'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xppR9j27emMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph_proj_df = pd.DataFrame(dict(G_proj.nodes(data=True))).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE0qrma1emS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph_proj_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxrgC26ZemHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the 5 most central for each identified community\n",
        "user_per_com = graph_proj_df.groupby('community')['eigenvector_centrality'].nlargest(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMF1j7RdfTr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_per_com"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsT8FhR1fTyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "profile = instaloader.Profile.from_id(L.context, 258805188)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoodYltCfT2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(profile.biography)\n",
        "print(profile.username)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqA4Lqe2WlPh",
        "colab_type": "text"
      },
      "source": [
        "Also, download it in the `Gephi` format. In case you don't have it installed, get it here: \n",
        "https://gephi.org/users/download/\n",
        "\n",
        "Play a bit around with visualizations. You can also do some of th common analysis (density, community detection etc...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH0LM2pcW2ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nx.write_gexf(G_proj, 'G_proj.gexf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aclY_cK9WFms",
        "colab_type": "text"
      },
      "source": [
        "Now lets do some blockmodelling :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1PQxqHPWYnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the network (you might get a warning message the first time - then do it again)\n",
        "nx.draw(G_proj,with_labels=True,node_color='#FFA0A0', node_size=500)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVivi2JiYdxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to matrix (numpy.matrix)\n",
        "mat=nx.adjacency_matrix(G_proj).todense()\n",
        "\n",
        "# Extract the node labels into a list - useful later on\n",
        "nodelabels=list(G_proj.nodes())\n",
        "\n",
        "# Display the sociomatrix\n",
        "bm.displaySociomatrix(mat,nodelabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU-HsA1rhGkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate indirect structural equivalence (Hamming distances)\n",
        "dist=bm.indirectSEhamming(mat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EntIhxE2o1Cw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the distance matrix\n",
        "print(dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgLZ7S1tpYar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to a condensed distance matrix\n",
        "\n",
        "dist_cond = sc.spatial.distance.squareform(dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sztErRgnpc4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dist_cond)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7792mQdHpdAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using the (non-weighted) average clustering approach, we create our clustering object\n",
        "Z=sch.linkage(dist_cond, method='complete')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amsYuFkYpdEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Then we can plot the dendrogram for this particular hierarchical clustering\n",
        "plt.figure(figsize=(10, 7))\n",
        "sch.dendrogram(Z,labels=nodelabels) # ...using the nodelabels we extracted in the beginning\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItuNPZRSpdHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We use the fcluster function to \"cut\" the dendrogram at a suitable level. First set that threshold/cutoff value:\n",
        "threshold=200\n",
        "\n",
        "partition = sch.fcluster(Z,threshold,'distance')\n",
        "\n",
        "# This 'partition' object is a 1-dimensional array (numpy.ndarray), indicating (for each node) which position it belongs to\n",
        "\n",
        "# Have a look at it:\n",
        "print(partition)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h2r4vrhp9k2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check that you got the number of partitions that you wanted\n",
        "len(np.unique(partition))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvB6cnt_qTwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# An alternative (and better) way to store this partition is in the form of a dictionary, of lists\n",
        "# In the blockmodeling library, I have created a function that generates such a dictionary, from your partition list\n",
        "\n",
        "blockdict=bm.createBlockdict(partition)\n",
        "\n",
        "# Display it and you will see\n",
        "bm.displayBlockdict(blockdict,nodelabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk-ZrZtXqY81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the nodelabels, you can display the final blockmodel\n",
        "\n",
        "bm.displayBlockmodel(mat,blockdict,nodelabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NODVt4hIqcKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "densityBI=bm.calcDensityBlockimage(mat,blockdict)\n",
        "\n",
        "print(np.around(densityBI,decimals=2))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}